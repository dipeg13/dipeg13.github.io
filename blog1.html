<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="Blog Post 1" />
    <title>K-Means</title>
    <link href="css/styles.css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        .content {
            width: 90%;         /* Set a specific width */
            margin-left: auto;   /* Automatically calculate left margin */
            margin-right: auto;  /* Automatically calculate right margin */
            padding: 10px;
        }
    </style>
</head>
<body>
    <div class="content">
        <h2 style="text-align: center;">The K-Means Algorithm</h2>

        <p>Date: October 18, 2024</p>

        <p>
            Clustering is the machine learning task that is seeks to group data points into clusters, based on a
            similarity measure. The basic difference between clustering and classification, is the fact that clustering,
            in contrast to classification, is an unsupervised task. In order to conduct classification, one has to train
            a model (classifier) based on labeled data points. In that essence, supposing that we have a dataset
            \( \mathcal{X} = \{ \vec{x}_1,\ldots,\vec{x}_n\} \) and a set of labels \( \mathcal{L}=\{l_1,\ldots,l_k\}
            \), the goal of classification is to estimate the map \( f:\mathcal{X}\rightarrow\mathcal{L} \). On the
            other hand, in clustering, no such \( \mathcal{L} \) set of ground truth exists.
        </p>

        <p>One of the most commonly used clustering algorithms is K-Means. Given a distance metric
            \( d:\mathcal{X}\times\mathcal{X}\rightarrow\mathbb{R}_+ \), K-Means groups the data points of
            \( \mathcal{X} \) in K-groups. Below we describe the basic K-Means algorithm

            \[
            \begin{algorithmic}[1]
                \STATE \mathcal{C} =\{ C_1,\ldots, C_K \} \gets Initialize centroids
                \FOR{ \( i=1,\ldots,n\) }
                    \STATE Assign every data point \vec{x}_j\in\mathcal{X} to the cluster that corresponds to the closest C_i, with respect to d
                    \STATE Update clusters' centroids as C_i = \frac{1}{|C_i|} \sum_{\vec{x}_j\in C_i} x_j
            \end{algorithmic}
            \]</p>
        <a href="index.html" class="btn btn-primary">Back to Blog</a>
    </div>
</body>
</html>
